# data:
data_dir: ../datasets/  # path to the unzipped dataset directories(H36m/AMASS/3DPW)
dataset: h36m_3d  # amass_3d
body_model_dir: ../body_models/smpl_skeleton.npz
input_n: 10  # number of model's input frames
output_n: 25  # number of model's output frames.

# model:
model: stsgcn_transformer
n_head : 6
num_layers: 3
n_stgcnn_layers: 9  # number of stgcnn layers
n_ccnn_layers: 2  # number of layers for the Coordinate-Channel Convolution
n_tcnn_layers: 4  # number of layers for the Time-Extrapolator Convolution
ccnn_kernel_size: [1, 1]  # kernel for the C-CNN layers
tcnn_kernel_size: [3, 3]  # kernel for the Time-Extrapolator CNN layers
embedding_dim: 40  # dimensions for the coordinates of the embedding
input_dim: 3  # dimensions of the input coordinates
st_gcnn_dropout: 0.1  # st-gcnn dropout
ccnn_dropout: 0.0  # ccnn dropout
tcnn_dropout: 0.0  # tcnn dropout

# run:
mode: train  # choices=['train','test','viz']. Choose to train, test or visualize from the model. Either train, test or viz.
optimizer: adam
scheduler: multi_step_lr
seed: 42
n_epochs: 90  # 50,100
batch_size: 256  # batch size
num_workers: 0  # 0 means use the same thread for preparing data
lr: 0.5  # 0.01 for stsgcn Learning rate of the optimizer
weight_decay: 0.00001
use_scheduler: True  # use MultiStepLR scheduler
early_stop_patience: 100
milestones: [5, 12, 25, 70]  # milestones: [15, 25, 35, 40]
gamma: 0.5  # gamma correction to the learning rate, after reaching the milestone epochs
clip_grad: null  # select max norm to clip gradients
log_dir: ../logs/

# visualization:
visualize_from: test  # ['train','val','test']. Choose data split to visualize from(train-val-test).
n_viz: 2  # Numbers of sequences to visualize for each action